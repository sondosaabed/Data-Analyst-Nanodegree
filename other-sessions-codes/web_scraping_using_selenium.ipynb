{"cells":[{"cell_type":"markdown","id":"7981201b-d1e2-4fb6-a416-9ef5de0765bb","metadata":{"id":"7981201b-d1e2-4fb6-a416-9ef5de0765bb"},"source":["## Web Scraping using Selenium webdriver and webdriver_manager"]},{"cell_type":"code","execution_count":1,"id":"ddfa7df2-45ab-482d-84e3-343e02a6289a","metadata":{"id":"ddfa7df2-45ab-482d-84e3-343e02a6289a","executionInfo":{"status":"ok","timestamp":1721833690376,"user_tz":-180,"elapsed":14612,"user":{"displayName":"Alaa' Omar","userId":"04274581550977179518"}},"outputId":"3a636093-5cf4-4876-debd-7ddc7b2de9f6","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting selenium\n","  Downloading selenium-4.23.1-py3-none-any.whl (9.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n","Collecting trio~=0.17 (from selenium)\n","  Downloading trio-0.26.0-py3-none-any.whl (475 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.7/475.7 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting trio-websocket~=0.9 (from selenium)\n","  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n","Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.7.4)\n","Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n","Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n","Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.7)\n","Collecting outcome (from trio~=0.17->selenium)\n","  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n","Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.2)\n","Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n","  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n","Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n","Successfully installed h11-0.14.0 outcome-1.3.0.post0 selenium-4.23.1 trio-0.26.0 trio-websocket-0.11.1 wsproto-1.2.0\n"]}],"source":["# Install Selenium -\n","!pip install selenium"]},{"cell_type":"markdown","id":"db9dd02e-a130-4010-9fe2-e02c02c87a90","metadata":{"id":"db9dd02e-a130-4010-9fe2-e02c02c87a90"},"source":["To set up the WebDriver you need to install the suitable version of your preferred browser manually on your local machine. But if you don't want to do that, you can use the <b>webdriver_manager</b> package.<br>\n","At First you need to install the package:"]},{"cell_type":"code","execution_count":2,"id":"5060bad3-a68a-453c-b7dd-ca206d3f8073","metadata":{"id":"5060bad3-a68a-453c-b7dd-ca206d3f8073","executionInfo":{"status":"ok","timestamp":1721833698630,"user_tz":-180,"elapsed":8258,"user":{"displayName":"Alaa' Omar","userId":"04274581550977179518"}},"outputId":"0a2d9c57-d97f-451a-c97b-055e3e9efc3b","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting webdriver_manager\n","  Downloading webdriver_manager-4.0.1-py2.py3-none-any.whl (27 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from webdriver_manager) (2.31.0)\n","Collecting python-dotenv (from webdriver_manager)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from webdriver_manager) (24.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver_manager) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver_manager) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver_manager) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver_manager) (2024.7.4)\n","Installing collected packages: python-dotenv, webdriver_manager\n","Successfully installed python-dotenv-1.0.1 webdriver_manager-4.0.1\n"]}],"source":["# Install webdriver manager\n","!pip install webdriver_manager"]},{"cell_type":"markdown","id":"0651a0d6-0f90-44d3-8f1d-9c1dc1366acf","metadata":{"id":"0651a0d6-0f90-44d3-8f1d-9c1dc1366acf"},"source":["Then import selenium web driver and the manager of your preferred browser:"]},{"cell_type":"code","execution_count":3,"id":"75311528-81d6-42d5-982d-ab1c96f457c8","metadata":{"id":"75311528-81d6-42d5-982d-ab1c96f457c8","executionInfo":{"status":"ok","timestamp":1721833700458,"user_tz":-180,"elapsed":514,"user":{"displayName":"Alaa' Omar","userId":"04274581550977179518"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","# Import selenium webdriver and\n","from selenium import webdriver\n","from selenium.webdriver.common.by import By\n","\n","# for Selenium 3 you need to import the service by uncommenting the following line,\n","# but for Selenium 4 you don't have to\n","#from selenium.webdriver.chrome.service import Service\n","\n","# Import the webdriver manager of your browser, ie: chrome\n","from webdriver_manager.chrome import ChromeDriverManager"]},{"cell_type":"markdown","id":"0260002b-db74-4c20-bef9-bcbffa1a421d","metadata":{"id":"0260002b-db74-4c20-bef9-bcbffa1a421d"},"source":["<b>If you want learn more about how to set-up and use webdriver_manager, you can visit [this page](https://pypi.org/project/webdriver-manager/) </b> <br>"]},{"cell_type":"markdown","id":"8d339d7f-bcda-4afe-bd97-412599a647af","metadata":{"id":"8d339d7f-bcda-4afe-bd97-412599a647af"},"source":["Now you are ready to set up the WebDriver and start scraping: <br><br>\n","Let's say that we want to scrape the following web page: https://www.scrapethissite.com/pages/forms <br>\n","this page contains data about Hockey Teams in USA, which is taken from a database of NHL team stats since 1990 to 2011."]},{"cell_type":"code","execution_count":null,"id":"f2c0d367-8274-4a46-a210-6fe10d3f03b6","metadata":{"id":"f2c0d367-8274-4a46-a210-6fe10d3f03b6","outputId":"7cd2d2d9-4a23-4e95-ae9f-9adeec121eb2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Team Name Year Wins Losses OT Losses Win % Goals For (GF) Goals Against (GA) + / -\n","Los Angeles Kings 1990 46 24 0.575 340 254 86\n","Los Angeles Kings 1991 35 31 0.438 287 296 -9\n","Los Angeles Kings 1992 39 35 0.464 338 340 -2\n","Los Angeles Kings 1993 27 45 0.321 294 322 -28\n","Los Angeles Kings 1994 16 23 0.333 142 174 -32\n","Los Angeles Kings 1995 24 40 0.293 256 302 -46\n","Los Angeles Kings 1996 28 43 0.341 214 268 -54\n","Los Angeles Kings 1997 38 33 0.463 227 225 2\n","Los Angeles Kings 1998 32 45 0.39 189 222 -33\n","Los Angeles Kings 1999 39 27 4 0.476 245 228 17\n","Los Angeles Kings 2000 38 28 3 0.463 252 228 24\n","Los Angeles Kings 2001 40 27 4 0.488 214 190 24\n","Los Angeles Kings 2002 33 37 6 0.402 203 221 -18\n","Los Angeles Kings 2003 28 29 9 0.341 205 217 -12\n","Los Angeles Kings 2005 42 35 5 0.512 249 270 -21\n","Los Angeles Kings 2006 27 41 14 0.329 227 283 -56\n","Los Angeles Kings 2007 32 43 7 0.39 231 266 -35\n","Los Angeles Kings 2008 34 37 11 0.415 207 234 -27\n","Los Angeles Kings 2009 46 27 9 0.561 241 219 22\n","Los Angeles Kings 2010 46 30 6 0.561 219 198 21\n","Los Angeles Kings 2011 40 27 15 0.488 194 179 15\n"]}],"source":["# Set up the WebDriver\n","service = Service(ChromeDriverManager().install())\n","driver = webdriver.Chrome(service=service)\n","\n","# Define the URL that the driver will get\n","# the URL that contains the data you are going to scrape\n","driver.get(\"https://www.scrapethissite.com/pages/forms\")\n","\n","# Search form submission,\n","# let's suppose that We want to use the input search field to filter the results of the data table\n","# ie: get all data where the team name is 'Los Angeles Kings'\n","# At first, Find the element of the input field\n","q = driver.find_element(By.ID, \"q\")\n","\n","# Then, Fill the input with your search keyword\n","q.send_keys(\"Los Angeles Kings\")\n","\n","# Then, submit the form to execute the filter process and get the results\n","q.submit()\n","\n","# Print all the filtered table values\n","table = driver.find_element(By.CLASS_NAME, \"table\")\n","print(table.text)\n","\n","# Or, you can iterate the output data and save them\n","datatable = []\n","\n","# Find all teams data from the filtered table\n","teams = table.find_elements(By.CLASS_NAME, \"team\")\n","\n","# Iterate all the teams to get the wanted data, then append the results to the datatable\n","for team in teams:\n","    team_name = team.find_element(By.CLASS_NAME, \"name\").text.strip()\n","    year = team.find_element(By.CLASS_NAME, \"year\").text.strip()\n","    wins = team.find_element(By.CLASS_NAME, \"wins\").text.strip()\n","    losses = team.find_element(By.CLASS_NAME, \"losses\").text.strip()\n","\n","    datatable.append({\n","        'team_name': team_name,\n","        'year': year,\n","        'wins': wins,\n","        'losses': losses\n","    })\n","\n","\n","# After finishing our scraping and getting all the wanted data, we must quit the driver\n","driver.quit()\n"]},{"cell_type":"code","execution_count":null,"id":"2e6a528f-736c-49a6-870c-2fbd95efda85","metadata":{"id":"2e6a528f-736c-49a6-870c-2fbd95efda85","outputId":"5f468bd1-ab38-43b8-f864-4496e5167362"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>team_name</th>\n","      <th>year</th>\n","      <th>wins</th>\n","      <th>losses</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Los Angeles Kings</td>\n","      <td>1990</td>\n","      <td>46</td>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Los Angeles Kings</td>\n","      <td>1991</td>\n","      <td>35</td>\n","      <td>31</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Los Angeles Kings</td>\n","      <td>1992</td>\n","      <td>39</td>\n","      <td>35</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Los Angeles Kings</td>\n","      <td>1993</td>\n","      <td>27</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Los Angeles Kings</td>\n","      <td>1994</td>\n","      <td>16</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Los Angeles Kings</td>\n","      <td>1995</td>\n","      <td>24</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Los Angeles Kings</td>\n","      <td>1996</td>\n","      <td>28</td>\n","      <td>43</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Los Angeles Kings</td>\n","      <td>1997</td>\n","      <td>38</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Los Angeles Kings</td>\n","      <td>1998</td>\n","      <td>32</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Los Angeles Kings</td>\n","      <td>1999</td>\n","      <td>39</td>\n","      <td>27</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Los Angeles Kings</td>\n","      <td>2000</td>\n","      <td>38</td>\n","      <td>28</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Los Angeles Kings</td>\n","      <td>2001</td>\n","      <td>40</td>\n","      <td>27</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Los Angeles Kings</td>\n","      <td>2002</td>\n","      <td>33</td>\n","      <td>37</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Los Angeles Kings</td>\n","      <td>2003</td>\n","      <td>28</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Los Angeles Kings</td>\n","      <td>2005</td>\n","      <td>42</td>\n","      <td>35</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>Los Angeles Kings</td>\n","      <td>2006</td>\n","      <td>27</td>\n","      <td>41</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>Los Angeles Kings</td>\n","      <td>2007</td>\n","      <td>32</td>\n","      <td>43</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>Los Angeles Kings</td>\n","      <td>2008</td>\n","      <td>34</td>\n","      <td>37</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>Los Angeles Kings</td>\n","      <td>2009</td>\n","      <td>46</td>\n","      <td>27</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Los Angeles Kings</td>\n","      <td>2010</td>\n","      <td>46</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>Los Angeles Kings</td>\n","      <td>2011</td>\n","      <td>40</td>\n","      <td>27</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            team_name  year wins losses\n","0   Los Angeles Kings  1990   46     24\n","1   Los Angeles Kings  1991   35     31\n","2   Los Angeles Kings  1992   39     35\n","3   Los Angeles Kings  1993   27     45\n","4   Los Angeles Kings  1994   16     23\n","5   Los Angeles Kings  1995   24     40\n","6   Los Angeles Kings  1996   28     43\n","7   Los Angeles Kings  1997   38     33\n","8   Los Angeles Kings  1998   32     45\n","9   Los Angeles Kings  1999   39     27\n","10  Los Angeles Kings  2000   38     28\n","11  Los Angeles Kings  2001   40     27\n","12  Los Angeles Kings  2002   33     37\n","13  Los Angeles Kings  2003   28     29\n","14  Los Angeles Kings  2005   42     35\n","15  Los Angeles Kings  2006   27     41\n","16  Los Angeles Kings  2007   32     43\n","17  Los Angeles Kings  2008   34     37\n","18  Los Angeles Kings  2009   46     27\n","19  Los Angeles Kings  2010   46     30\n","20  Los Angeles Kings  2011   40     27"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# Save the data into a Dataframe, and explore it\n","teams_filtered = pd.DataFrame(datatable)\n","teams_filtered"]},{"cell_type":"markdown","id":"b3c0e22b-3715-4f83-b0cf-a5ff45b95749","metadata":{"id":"b3c0e22b-3715-4f83-b0cf-a5ff45b95749"},"source":["<b>What if I want to get all the table data without any filters?</b> Here we can see that the data is rendered over several pages within the table which is called pagination, each page table contains 25 records. Getting data from all pages might be more complex, but we can do it like the following:"]},{"cell_type":"code","execution_count":null,"id":"05f6e86c-18d6-4bba-b101-2edee5a901e1","metadata":{"id":"05f6e86c-18d6-4bba-b101-2edee5a901e1"},"outputs":[],"source":["def scrape_data():\n","    \"\"\"\n","    Scrape data from a specific URL.\n","\n","    Parameters:\n","    None\n","\n","    Returns:\n","    data\n","    \"\"\"\n","    # Set up the WebDriver\n","    service = Service(ChromeDriverManager().install())\n","    driver = webdriver.Chrome(service=service)\n","\n","    # Define the URL that the driver will get\n","    # the URL that contains the data you are going to scrape\n","    driver.get(\"https://www.scrapethissite.com/pages/forms\")\n","\n","    data = []\n","\n","    # Fing the 'pagination' element that contains the pages\n","    pagination = driver.find_elements(By.CSS_SELECTOR, \"ul.pagination>li\")\n","\n","    # By default the first rendered page has page number 1\n","    page_number = 1\n","\n","    # Etirate through each page in the pagination element to get the its data\n","    for page in pagination:\n","\n","        try:\n","\n","            # Page numbers are clickable, so we need to click the page number to render its data\n","            # to do that in code, we need first to find the'href' attribute for the page number\n","            # then click it using code to render the data\n","            page = driver.find_element(By.CSS_SELECTOR, f\"a[href='/pages/forms/?page_num={page_number}']\")\n","            page.click()\n","\n","            # Find all teams data from the rendered table\n","            teams = driver.find_elements(By.CLASS_NAME, \"team\")\n","\n","            # Iterate all the teams to get the wanted data, then append the results to the 'data'\n","            for team in teams:\n","                team_name = team.find_element(By.CLASS_NAME, \"name\").text.strip()\n","                year = team.find_element(By.CLASS_NAME, \"year\").text.strip()\n","                wins = team.find_element(By.CLASS_NAME, \"wins\").text.strip()\n","                losses = team.find_element(By.CLASS_NAME, \"losses\").text.strip()\n","\n","                data.append({\n","                    'team_name': team_name,\n","                    'year': year,\n","                    'wins': wins,\n","                    'losses': losses\n","                })\n","        except:\n","            # If the page number does not exist in the pagination, then don't raise an exception and continue\n","            continue\n","\n","        # Set the next page number\n","        page_number = page_number + 1\n","\n","    # After finishing our scraping and getting all the wanted data, we must quit the driver\n","    driver.quit()\n","\n","    # return the output data\n","    return data"]},{"cell_type":"code","execution_count":null,"id":"70e5e0a9-a58d-410b-acec-0275c47d69f9","metadata":{"id":"70e5e0a9-a58d-410b-acec-0275c47d69f9"},"outputs":[],"source":["# Call the scraper function\n","scraped_data = scrape_data()"]},{"cell_type":"code","execution_count":null,"id":"8901f7b3-aa53-4823-84b3-353b139cffba","metadata":{"id":"8901f7b3-aa53-4823-84b3-353b139cffba","outputId":"b12f5061-c252-40cd-a9a7-3286d81d0665"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>team_name</th>\n","      <th>year</th>\n","      <th>wins</th>\n","      <th>losses</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Boston Bruins</td>\n","      <td>1990</td>\n","      <td>44</td>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Buffalo Sabres</td>\n","      <td>1990</td>\n","      <td>31</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Calgary Flames</td>\n","      <td>1990</td>\n","      <td>46</td>\n","      <td>26</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Chicago Blackhawks</td>\n","      <td>1990</td>\n","      <td>49</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Detroit Red Wings</td>\n","      <td>1990</td>\n","      <td>34</td>\n","      <td>38</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>577</th>\n","      <td>Tampa Bay Lightning</td>\n","      <td>2011</td>\n","      <td>38</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th>578</th>\n","      <td>Toronto Maple Leafs</td>\n","      <td>2011</td>\n","      <td>35</td>\n","      <td>37</td>\n","    </tr>\n","    <tr>\n","      <th>579</th>\n","      <td>Vancouver Canucks</td>\n","      <td>2011</td>\n","      <td>51</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>580</th>\n","      <td>Washington Capitals</td>\n","      <td>2011</td>\n","      <td>42</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>581</th>\n","      <td>Winnipeg Jets</td>\n","      <td>2011</td>\n","      <td>37</td>\n","      <td>35</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>582 rows × 4 columns</p>\n","</div>"],"text/plain":["               team_name  year wins losses\n","0          Boston Bruins  1990   44     24\n","1         Buffalo Sabres  1990   31     30\n","2         Calgary Flames  1990   46     26\n","3     Chicago Blackhawks  1990   49     23\n","4      Detroit Red Wings  1990   34     38\n","..                   ...   ...  ...    ...\n","577  Tampa Bay Lightning  2011   38     36\n","578  Toronto Maple Leafs  2011   35     37\n","579    Vancouver Canucks  2011   51     22\n","580  Washington Capitals  2011   42     32\n","581        Winnipeg Jets  2011   37     35\n","\n","[582 rows x 4 columns]"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# Save the data into a Dataframe, and explore it\n","teams_data = pd.DataFrame(scraped_data)\n","teams_data"]},{"cell_type":"code","execution_count":null,"id":"a954c675-0389-4858-a206-9976f0230246","metadata":{"id":"a954c675-0389-4858-a206-9976f0230246","outputId":"16456177-a5f2-47d4-fcc4-3450bd1fd627"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 582 entries, 0 to 581\n","Data columns (total 4 columns):\n"," #   Column     Non-Null Count  Dtype \n","---  ------     --------------  ----- \n"," 0   team_name  582 non-null    object\n"," 1   year       582 non-null    object\n"," 2   wins       582 non-null    object\n"," 3   losses     582 non-null    object\n","dtypes: object(4)\n","memory usage: 18.3+ KB\n"]}],"source":["# explore the scraped data\n","teams_data.info()"]},{"cell_type":"code","execution_count":null,"id":"6390cf4e-3772-4401-b822-22a5f659098a","metadata":{"id":"6390cf4e-3772-4401-b822-22a5f659098a"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}